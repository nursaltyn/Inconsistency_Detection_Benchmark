{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this notebook, we identify model majority labels over 5 runs, for 5-class and 3-class setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold = pd.read_csv(r\"../data/qualtrics_survey/results/df_gold_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_5 = ['Unrelated', 'Consistent', 'Indirect inconsistency', \"Factual inconsistency\", 'Surface contradiction']                             \n",
    "classes_3 = ['Unrelated', 'Consistent', 'Inconsistent']\n",
    "classes_5_to_3 = {'Unrelated': 'Unrelated', 'Consistent': 'Consistent', 'Indirect inconsistency': 'Inconsistent', \"Factual inconsistency\": 'Inconsistent', 'Surface contradiction': 'Inconsistent'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify majority (3 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold['LLaMA 8B majority 3 class'] = 0\n",
    "for i in range(len(df_gold)):\n",
    "    list_answers = eval(df_gold['LLaMA 8B 5 runs'][i])\n",
    "    list_answers = [classes_5_to_3[el] for el in list_answers]\n",
    "    counter = Counter(list_answers)\n",
    "    max_count = max(counter.values())\n",
    "    top_labels = [label for label, count in counter.items() if count == max_count]\n",
    "    majority = random.choice(top_labels)\n",
    "    df_gold['LLaMA 8B majority 3 class'][i] = majority\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold['LLaMA 70B majority 3 class'] = 0\n",
    "for i in range(len(df_gold)):\n",
    "    list_answers = eval(df_gold['LLaMA 70B 5 runs'][i])\n",
    "    list_answers = [classes_5_to_3[el] for el in list_answers]\n",
    "    counter = Counter(list_answers)\n",
    "    max_count = max(counter.values())\n",
    "    top_labels = [label for label, count in counter.items() if count == max_count]\n",
    "    majority = random.choice(top_labels)\n",
    "    df_gold['LLaMA 70B majority 3 class'][i] = majority\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold['ChatGPT-3.5 majority 3 class'] = 0\n",
    "for i in range(len(df_gold)):\n",
    "    list_answers = eval(df_gold['ChatGPT-3.5 5 runs'][i])\n",
    "    list_answers = [classes_5_to_3[el] for el in list_answers]\n",
    "    counter = Counter(list_answers)\n",
    "    max_count = max(counter.values())\n",
    "    top_labels = [label for label, count in counter.items() if count == max_count]\n",
    "    majority = random.choice(top_labels)\n",
    "    df_gold['ChatGPT-3.5 majority 3 class'][i] = majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold['ChatGPT-4 majority 3 class'] = 0\n",
    "for i in range(len(df_gold)):\n",
    "    list_answers = eval(df_gold['ChatGPT-4 5 runs'][i])\n",
    "    list_answers = [classes_5_to_3[el] for el in list_answers]\n",
    "    counter = Counter(list_answers)\n",
    "    max_count = max(counter.values())\n",
    "    top_labels = [label for label, count in counter.items() if count == max_count]\n",
    "    majority = random.choice(top_labels)\n",
    "    df_gold['ChatGPT-4 majority 3 class'][i] = majority\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify majority (5 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold['LLaMA 8B majority'] = 0\n",
    "for i in range(len(df_gold)):\n",
    "    list_answers = df_gold['LLaMA 8B 5 runs'][i]\n",
    "    counter = Counter(list_answers)\n",
    "    max_count = max(counter.values())\n",
    "    top_labels = [label for label, count in counter.items() if count == max_count]\n",
    "    majority = random.choice(top_labels)\n",
    "    df_gold['LLaMA 8B majority'][i] = majority\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold['LLaMA 70B majority'] = 0\n",
    "for i in range(len(df_gold)):\n",
    "    list_answers = df_gold['LLaMA 70B 5 runs'][i]\n",
    "    counter = Counter(list_answers)\n",
    "    max_count = max(counter.values())\n",
    "    top_labels = [label for label, count in counter.items() if count == max_count]\n",
    "    majority = random.choice(top_labels)\n",
    "    df_gold['LLaMA 70B majority'][i] = majority\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold['ChatGPT-3.5 majority'] = 0\n",
    "for i in range(len(df_gold)):\n",
    "    list_answers = df_gold['ChatGPT-3.5 5 runs'][i]\n",
    "    counter = Counter(list_answers)\n",
    "    max_count = max(counter.values())\n",
    "    top_labels = [label for label, count in counter.items() if count == max_count]\n",
    "    majority = random.choice(top_labels)\n",
    "    df_gold['ChatGPT-3.5 majority'][i] = majority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold['ChatGPT-4 majority'] = 0\n",
    "for i in range(len(df_gold)):\n",
    "    list_answers = df_gold['ChatGPT-4 5 runs'][i]\n",
    "    counter = Counter(list_answers)\n",
    "    max_count = max(counter.values())\n",
    "    top_labels = [label for label, count in counter.items() if count == max_count]\n",
    "    majority = random.choice(top_labels)\n",
    "    df_gold['ChatGPT-4 majority'][i] = majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold.to_csv(r\"../data/qualtrics_survey/results/df_gold_all.csv\", index='False')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
