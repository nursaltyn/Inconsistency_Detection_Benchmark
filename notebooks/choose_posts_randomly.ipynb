{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import math\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove non-texts, pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/Nursulu_1/Downloads/ContraDetect/automatic_stance_detection/afd_texts/afd_website_1900.json\", 'r', encoding='utf-8') as json_file:\n",
    "    website_dicts = json.load(json_file)\n",
    "\n",
    "with open(\"C:/Users/Nursulu_1/Downloads/ContraDetect/automatic_stance_detection/afd_texts/afd_instagram_1775.json\", 'r', encoding='utf-8') as json_file:\n",
    "    instagram = json.load(json_file)\n",
    "    \n",
    "with open(\"C:/Users/Nursulu_1/Downloads/ContraDetect/automatic_stance_detection/afd_texts/afd_youtube_50.json\", 'r', encoding='utf-8') as json_file:\n",
    "    youtube = json.load(json_file)\n",
    "    \n",
    "website = []\n",
    "for el in website_dicts:\n",
    "    website.append(el['content'])\n",
    "    \n",
    "afd_texts = []\n",
    "afd_texts.extend(website)\n",
    "afd_texts.extend(instagram)\n",
    "afd_texts.extend(youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "afd_texts = list(set(afd_texts))\n",
    "afd_texts = [s for s in afd_texts if not s.isdigit()]\n",
    "random.shuffle(afd_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2260"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(afd_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"sk-proj-3KhQdlgMCuoQc6EL2y1ZT3BlbkFJYHG9JgPGpOLsRnDSKuSs\")\n",
    "assistant_id = \"asst_gn7CDBb1LyunO5AyquAROWsY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_summary_generation(text):\n",
    "\n",
    "    statement = text\n",
    "    if str(statement) not in [\"NaN\", \"nan\"]:\n",
    "        try:\n",
    "            # Create a thread with a message.\n",
    "            thread = client.beta.threads.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        # Update this with the query you want to use.\n",
    "                        \"content\": statement,\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        # Submit the thread to the assistant (as a new run).\n",
    "            run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant_id)\n",
    "\n",
    "            # Wait for run to complete.\n",
    "            while run.status != \"completed\":\n",
    "                run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "                time.sleep(1)\n",
    "            # else:\n",
    "            #     print(f\"üèÅ Run Completed!\")\n",
    "\n",
    "            # Get the latest message from the thread.\n",
    "            message_response = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "            messages = message_response.data\n",
    "\n",
    "            # Print the latest message.\n",
    "            latest_message = messages[0]\n",
    "            return latest_message.content[0].text.value\n",
    "        except:\n",
    "            print(f\"Run went wrong\")\n",
    "            return None\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize every text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = []\n",
    "text2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [36:22<04:47,  8.98s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run went wrong\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [42:24<00:00, 12.72s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(200)):\n",
    "    to_sum_1 = random.choice(afd_texts)\n",
    "    to_sum_2 = random.choice(afd_texts)\n",
    "    if to_sum_1 == to_sum_2:\n",
    "        to_sum_2 = random.choice(afd_texts)\n",
    "    sum_1 = run_summary_generation(to_sum_1)\n",
    "    text1.append(sum_1)\n",
    "    sum_2 = run_summary_generation(to_sum_2)\n",
    "    text2.append(sum_2)\n",
    "    with open('text1_unrelated.json', 'w') as f:\n",
    "        json.dump(text1, f)\n",
    "    with open('text2_unrelated.json', 'w') as f:\n",
    "        json.dump(text2, f)\n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Nursulu_1\\Downloads\\ContraDetect\\automatic_stance_detection\\notebooks\\text1_unrelated_afd.json\") as f:\n",
    "    text1 = json.load(f)\n",
    "    \n",
    "with open(r\"C:\\Users\\Nursulu_1\\Downloads\\ContraDetect\\automatic_stance_detection\\notebooks\\text2_unrelated_afd.json\") as f:\n",
    "    text2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We believe that contrary to the prevailing narrative from mainstream parties and media, the mass immigration starting in 2015 has not resulted in a job miracle and peaceful integration, but rather catastrophic outcomes in terms of the labor market and crime rates, as highlighted by Saxony's AfD state parliament member Carsten H√ºtter.\n",
      "We believe that the increase in traffic accidents in Hamburg, particularly involving cyclists and e-scooter users, necessitates more traffic controls and improved safety measures for all road users.\n"
     ]
    }
   ],
   "source": [
    "t1 = random.choice(text1)\n",
    "print(t1)\n",
    "t2 = random.choice(text2)\n",
    "print(t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.index( \"We believe that it's essential to tune in and watch! üíôüì∫\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We believe that it's essential to tune in and watch! üíôüì∫\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.pop(156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unrelated = pd.DataFrame({\"Text 1\": text1, \"Text 2\": text2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unrelated.to_csv(\"df_unrelated_afd.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = [el for el in text2 if el != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "750/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5000/60)*15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
