{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"sk-proj-3KhQdlgMCuoQc6EL2y1ZT3BlbkFJYHG9JgPGpOLsRnDSKuSs\")\n",
    "prompt_5_types = \"asst_13QqvGJEmZcaizKEmeSZMQnC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_3_types = \"asst_zX008FyufXH0pgwjuUXAcZkX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(text):\n",
    "\n",
    "    try:\n",
    "        # Create a thread with a message.\n",
    "        thread = client.beta.threads.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    # Update this with the query you want to use.\n",
    "                    \"content\": text,\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    # Submit the thread to the assistant (as a new run).\n",
    "        run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=prompt_5_types)\n",
    "\n",
    "        # Wait for run to complete.\n",
    "        while run.status != \"completed\":\n",
    "            run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "            time.sleep(1)\n",
    "        # else:\n",
    "        #     print(f\"üèÅ Run Completed!\")\n",
    "\n",
    "        # Get the latest message from the thread.\n",
    "        message_response = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        messages = message_response.data\n",
    "\n",
    "        # Print the latest message.\n",
    "        latest_message = messages[0]\n",
    "        return latest_message.content[0].text.value\n",
    "    except:\n",
    "        print(f\"Run went wrong\")\n",
    "        return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label_and_explanation(text):\n",
    "    label_match = re.search(r\"Label:(.*?)Explanation:\", text, re.DOTALL)\n",
    "    label_text = label_match.group(1).strip() if label_match else text\n",
    "\n",
    "    # Extract text after \"Explanation\"\n",
    "    explanation_match = re.search(r\"Explanation:(.*)\", text, re.DOTALL)\n",
    "    explanation_text = explanation_match.group(1).strip() if explanation_match else text\n",
    "    \n",
    "    return label_text, explanation_text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun experiment 3 times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold = pd.read_csv(r\"C:\\Users\\Nursulu_1\\Downloads\\ContraDetect\\automatic_stance_detection\\data\\qualtrics_survey\\results\\df_gold_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = list(df_gold['Input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_run/answers_chatgpt4_turbo_5_types_run4.pkl', 'rb') as f:\n",
    "    answers_chatgpt4_turbo_5_types_run4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 698/698 [27:56<00:00,  2.40s/it] \n"
     ]
    }
   ],
   "source": [
    "# answers_chatgpt4_turbo_5_types_run4 = dict()\n",
    "for sample in tqdm(statements):\n",
    "    if sample not in answers_chatgpt4_turbo_5_types_run4:\n",
    "        answers_chatgpt4_turbo_5_types_run4[sample] = dict()\n",
    "        answer = predict_label(sample)\n",
    "        try:\n",
    "            label, explanation = extract_label_and_explanation(answer)\n",
    "            answers_chatgpt4_turbo_5_types_run4[sample]['label'] = label\n",
    "            answers_chatgpt4_turbo_5_types_run4[sample]['explanation'] = explanation\n",
    "        except:\n",
    "            print(\"Couldn't parse the answer for sample\")\n",
    "            print(sample)\n",
    "            answers_chatgpt4_turbo_5_types_run4[sample]['label'] = answer\n",
    "        with open('new_run/answers_chatgpt4_turbo_5_types_run4.pkl', 'wb') as f:\n",
    "            pickle.dump(answers_chatgpt4_turbo_5_types_run4, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_chatgpt35_turbo_5_types_run5 = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_run/answers_chatgpt35_turbo_5_types_run2.pkl', 'rb') as f:\n",
    "    answers_chatgpt35_turbo_5_types_run2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 698/698 [55:07<00:00,  4.74s/it] \n"
     ]
    }
   ],
   "source": [
    "# answers_chatgpt35_turbo_5_types_run5 = dict()\n",
    "for sample in tqdm(statements):\n",
    "    answers_chatgpt35_turbo_5_types_run5[sample] = dict()\n",
    "    answer = predict_label(sample)\n",
    "    try:\n",
    "        label, explanation = extract_label_and_explanation(answer)\n",
    "        answers_chatgpt35_turbo_5_types_run5[sample]['label'] = label\n",
    "        answers_chatgpt35_turbo_5_types_run5[sample]['explanation'] = explanation\n",
    "    except:\n",
    "        print(\"Couldn't parse the answer for sample\")\n",
    "        print(sample)\n",
    "        answers_chatgpt35_turbo_5_types_run5[sample]['label'] = answer\n",
    "    with open('new_run/answers_chatgpt35_turbo_5_types_run5.pkl', 'wb') as f:\n",
    "        pickle.dump(answers_chatgpt35_turbo_5_types_run5, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label_3_types(text):\n",
    "\n",
    "    try:\n",
    "        # Create a thread with a message.\n",
    "        thread = client.beta.threads.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    # Update this with the query you want to use.\n",
    "                    \"content\": text,\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    # Submit the thread to the assistant (as a new run).\n",
    "        run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=prompt_3_types)\n",
    "\n",
    "        # Wait for run to complete.\n",
    "        while run.status != \"completed\":\n",
    "            run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "            time.sleep(1)\n",
    "        # else:\n",
    "        #     print(f\"üèÅ Run Completed!\")\n",
    "\n",
    "        # Get the latest message from the thread.\n",
    "        message_response = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        messages = message_response.data\n",
    "\n",
    "        # Print the latest message.\n",
    "        latest_message = messages[0]\n",
    "        return latest_message.content[0].text.value\n",
    "    except:\n",
    "        print(f\"Run went wrong\")\n",
    "        return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Nursulu_1\\Downloads\\ContraDetect\\automatic_stance_detection\\notebooks\\sample_to_responses_Part_1.pkl\", 'rb') as f:\n",
    "    sample_to_responses = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Nursulu_1\\Downloads\\ContraDetect\\automatic_stance_detection\\notebooks\\evaluating_models\\answers_chatgpt_3_types.pkl', 'rb') as f:\n",
    "    answers_chatgpt_3_types = pickle.load(f)\n",
    "with open(r'C:\\Users\\Nursulu_1\\Downloads\\ContraDetect\\automatic_stance_detection\\notebooks\\evaluating_models\\answers_chatgpt_3_types_350_700.pkl', 'rb') as f:\n",
    "    answers_chatgpt_3_types_pt2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### replace \"\\n\" with \"\\n\\n\"\n",
    "key_changes = dict()\n",
    "for el in answers_chatgpt_3_types_pt2.keys():\n",
    "    key_changes[el] = el.replace(\"\\n\", \"\\n\\n\")\n",
    "    \n",
    "# Rename keys\n",
    "for old_key, new_key in key_changes.items():\n",
    "    if old_key in answers_chatgpt_3_types_pt2:\n",
    "        answers_chatgpt_3_types_pt2[new_key] = answers_chatgpt_3_types_pt2.pop(old_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_samples = []\n",
    "for el in answers_chatgpt_3_types:\n",
    "    annotated_samples.append(el)\n",
    "for el in answers_chatgpt_3_types_pt2:\n",
    "    annotated_samples.append(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Nursulu_1\\Downloads\\ContraDetect\\automatic_stance_detection\\data\\qualtrics_survey\\all_samples_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold = pd.read_csv(r\"C:\\Users\\Nursulu_1\\Downloads\\ContraDetect\\automatic_stance_detection\\data\\qualtrics_survey\\results\\df_gold_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = list(df_gold['Input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(statements) - set(annotated_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_annotate = list(set(statements) - set(annotated_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text 1: Europe needs tax cuts, not new taxes.\\n\\nText 2: We support the EU having the ability to levy its own taxes instead of relying on national contributions.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_annotate[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 102/102 [17:16<00:00, 10.16s/it]\n"
     ]
    }
   ],
   "source": [
    "answers_chatgpt4_3_types = dict()\n",
    "for sample in tqdm(to_annotate):\n",
    "    answers_chatgpt4_3_types[sample] = dict()\n",
    "    answer = predict_label_3_types(sample)\n",
    "    try:\n",
    "        label, explanation = extract_label_and_explanation(answer)\n",
    "        answers_chatgpt4_3_types[sample]['label'] = label\n",
    "        answers_chatgpt4_3_types[sample]['explanation'] = explanation\n",
    "    except:\n",
    "        print(\"Couldn't parse the answer for sample\")\n",
    "        print(sample)\n",
    "        answers_chatgpt4_3_types[sample]['label'] = answer\n",
    "    with open('answers_chatgpt4_3_types_leftovers.pkl', 'wb') as f:\n",
    "        pickle.dump(answers_chatgpt4_3_types, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 700/700 [51:24<00:00,  4.41s/it] \n"
     ]
    }
   ],
   "source": [
    "answers_chatgpt35_turbo_3_types = dict()\n",
    "for sample in tqdm(statements):\n",
    "    answers_chatgpt35_turbo_3_types[sample] = dict()\n",
    "    answer = predict_label_3_types(sample)\n",
    "    try:\n",
    "        label, explanation = extract_label_and_explanation(answer)\n",
    "        answers_chatgpt35_turbo_3_types[sample]['label'] = label\n",
    "        answers_chatgpt35_turbo_3_types[sample]['explanation'] = explanation\n",
    "    except:\n",
    "        print(\"Couldn't parse the answer for sample\")\n",
    "        print(sample)\n",
    "        answers_chatgpt35_turbo_3_types[sample]['label'] = answer\n",
    "    with open('answers_chatgpt35_turbo_3_types.pkl', 'wb') as f:\n",
    "        pickle.dump(answers_chatgpt35_turbo_3_types, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 700/700 [49:19<00:00,  4.23s/it] \n"
     ]
    }
   ],
   "source": [
    "answers_chatgpt35_turbo_5_types = dict()\n",
    "for sample in tqdm(statements):\n",
    "    answers_chatgpt35_turbo_5_types[sample] = dict()\n",
    "    answer = predict_label(sample)\n",
    "    try:\n",
    "        label, explanation = extract_label_and_explanation(answer)\n",
    "        answers_chatgpt35_turbo_5_types[sample]['label'] = label\n",
    "        answers_chatgpt35_turbo_5_types[sample]['explanation'] = explanation\n",
    "    except:\n",
    "        print(\"Couldn't parse the answer for sample\")\n",
    "        print(sample)\n",
    "        answers_chatgpt35_turbo_5_types[sample]['label'] = answer\n",
    "    with open('answers_chatgpt35_turbo_5_types_350_700.pkl', 'wb') as f:\n",
    "        pickle.dump(answers_chatgpt35_turbo_5_types, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: run the second half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "answers_chatgpt_3_types = dict()\n",
    "for sample in tqdm(statements[350:]):\n",
    "    answers_chatgpt_3_types[sample] = dict()\n",
    "    answer = predict_label_3_types(sample)\n",
    "    try:\n",
    "        label, explanation = extract_label_and_explanation(answer)\n",
    "        answers_chatgpt_3_types[sample]['label'] = label\n",
    "        answers_chatgpt_3_types[sample]['explanation'] = explanation\n",
    "    except:\n",
    "        print(\"Couldn't parse the answer for sample\")\n",
    "        print(sample)\n",
    "        answers_chatgpt_3_types[sample]['label'] = answer\n",
    "    with open('answers_chatgpt_3_types_350_700.pkl', 'wb') as f:\n",
    "        pickle.dump(answers_chatgpt_3_types, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
