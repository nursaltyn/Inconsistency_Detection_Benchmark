{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nursulu_1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read samples from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples_df = pd.read_csv(r\"C:\\Users\\Nursulu_1\\Downloads\\ContraDetect\\automatic_stance_detection\\data\\qualtrics_survey\\all_samples_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples_df.columns = [\"Input\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Text 1: The first degree should remain free of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Text 1: Only states that consistently respect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Text 1: We have tightened the building regulat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Text 1: We want to make the teaching professio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Text 1: We support the proposal to increase th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>Text 1: We advocate for higher Erasmus+ schola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Text 1: We vote for the exclusive promotion of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>Text 1: We support equipping police forces wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>Text 1: If the government provides financial a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>Text 1: We support granting exceptions for clu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Input\n",
       "0    Text 1: The first degree should remain free of...\n",
       "1    Text 1: Only states that consistently respect ...\n",
       "2    Text 1: We have tightened the building regulat...\n",
       "3    Text 1: We want to make the teaching professio...\n",
       "4    Text 1: We support the proposal to increase th...\n",
       "..                                                 ...\n",
       "695  Text 1: We advocate for higher Erasmus+ schola...\n",
       "696  Text 1: We vote for the exclusive promotion of...\n",
       "697  Text 1: We support equipping police forces wit...\n",
       "698  Text 1: If the government provides financial a...\n",
       "699  Text 1: We support granting exceptions for clu...\n",
       "\n",
       "[700 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    ".# all_samples_df['Llama-3.3-70B-Instruct'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_5_types = '''You are a diligent annotator who is performing a crowdsourcing task. You will be given pairs of texts, which are statements made by a political party. Your task is to evaluate whether they are consistent with each other or not. Additionally, we will ask you to briefly explain your reasoning behind choosing the label.\n",
    "\n",
    "Please familiarize yourself with the evaluation scale.\n",
    "Evaluation scale \n",
    "(In growing order, the explanations will follow) \n",
    "Unrelated -> Consistent -> Indirect inconsistency -> Factual inconsistency -> Surface contradiction\n",
    "\n",
    "Surface contradiction\n",
    "\n",
    "If A is True, B is False, and vice versa. No external/specialized knowledge is required to detect contradiction, just understanding logical form/language in A and B.\n",
    "\n",
    "Example 1: a) All kikis are bobable. b) This kiki is not bobable.\n",
    "Explanation: the logical form here is: a) All A are B. b) This A is not B. These are mutually exclusive.\n",
    "\n",
    "Example 2: a) I love kikis. b) I think kikis are the most terrible thing on Earth.\n",
    "Explanation: knowing language here is enough to see a contradiction.\n",
    "\n",
    "In both examples, we don't have to know what \"kiki\" and \"bobable\" mean in the real world (no external knowledge is needed). The \"surface\" is enough to see a contradiction. \n",
    "\n",
    "Example 3: a) I support the yellow party.\n",
    "b) I'm against the yellow party.\n",
    "Explanation: To support something and to be against something are the opposites. It is enough to understand the language to detect a contradiction - thus, it is a Surface contradiction.\n",
    "\n",
    "Example 4: a) We oppose sending weapons to war zones.\n",
    "b) We voted in favor of sending 50 tanks to a country that was attacked.\n",
    "Explanation: To \"oppose sending weapons\" and \"vote in favor of sending 50 tanks\" express opposing attitudes. No knowledge beyond A and B is needed to see a contradiction, so it is a Surface contradiction.\n",
    "\n",
    "Factual inconsistency\n",
    "\n",
    "if A is True, it challenges the Truth of B.\n",
    "Having external knowledge about the world beyond what is said in A and B is required to see inconsistency. This knowledge can include laws of physics, principles of economics, international relations, etc., as well as real-world events and empirical evidence.\n",
    "\n",
    "Example 1: a) We will provide extensive social benefits. b) We will minimize all the taxes.\n",
    "Explanation: based on empirical evidence, increasing social benefits (pensions, subsidies, etc.) usually requires having high taxes. This knowledge is needed to detect inconsistency. \n",
    "Note that A and B are not mutually exclusive - maybe the government will take debt or use other ways to increase social benefits.\n",
    "However, based only on the information we have + empirical evidence, we can assume that A and B are Factually inconsistent.\n",
    "\n",
    "Example 2: a) We care about climate change and want to switch to renewable energy.\n",
    "b) We are planning to build 120 coal plants next year.\n",
    "Explanation: Coal is not a renewable energy source, and burning coal contributes to climate change. This knowledge is required to see the inconsistency, and it is not mentioned in A and B. Thus, A and B are Factually inconsistent.\n",
    "\n",
    "\n",
    "Example 3: a) We don’t support subsidies in agriculture and think they are bad for competition.\n",
    "b) We demand the maintenance and future doubling of the agricultural diesel refund.\n",
    "Explanation: Text A is against subsidies in agriculture. Text B supports diesel refund, which can be considered as a type of a subsidy. Knowing this is required to see a contradiction, thus, it is a Factual inconsistency.\n",
    "\n",
    "Indirect inconsistency\n",
    "\n",
    "If A is True, it doesn't directly challenge the Truth of B, and vice versa.\n",
    "However, A and B go in opposite directions with respect to some value/ideology (V).\n",
    "\n",
    "Example 1: a) We support financial aid for unemployed people. b) We are against financial aid for single mothers. \n",
    "Explanation: In A, the author supports financial aid for people who might be struggling financially, while B is implicitly against supporting them (since single mothers might be struggling financially too). However, A doesn't challenge the truth of B - they are just going in opposite political directions.\n",
    "\n",
    "Example 2: a) We voted in favor of increasing data privacy regulations.\n",
    "b) We are working on introducing very precise targeted advertising.\n",
    "Explanation: In text B, one should know that targeted advertising requires extensive user data to be more precise. Thus, text B goes against data privacy, while text A supports it. It is an Indirect inconsistency.\n",
    "\n",
    "Example 3: a) Our government is committed to leading the disarmament negotiations.\n",
    "b) The defense ministry has announced an increase in the benefits available for volunteers in the army.\n",
    "Explanation: Text A expresses a stance against militarization (leading the disarmament negotiations), while text B is pro-militarization (recruiting more volunteers in the army). Thus, there is an Indirect inconsistency between A and B.\n",
    "\n",
    "Consistent\n",
    "\n",
    "If A is True, B is also likely to be True, and vice versa.\n",
    "\n",
    "Example 1:\n",
    "a) I like classical music. b) I am going to a classical music concert today.\n",
    "\n",
    "Example 2:\n",
    "a) We believe that the current government is failing to address population decline effectively.\n",
    "b) We believe the government should prioritize the traditional family model.\n",
    "\n",
    "Example 3:\n",
    "a) We believe that determining asylum eligibility before individuals reach the country would significantly relieve the taxpayers. b) We support stricter border protection measures due to the large-scale family reunification migration.\n",
    "\n",
    "Unrelated\n",
    "\n",
    "The Truth of A doesn't affect the Truth of B, and vice versa.\n",
    "\n",
    "Example 1:\n",
    "a) All apples are red. b) I like sunny weather.\n",
    "\n",
    "Example 2:\n",
    "a) We think people should be able to obtain sick leave for mild illnesses for up to seven days.\n",
    "b) We believe that the left-leaning bias in public broadcasting journalism is a significant issue.\n",
    "\n",
    "Example 3:\n",
    "a) We oppose expanding surveillance measures that use facial recognition technology. b) We believe that the deportation of illegal migrants will help alleviate the housing shortage in our country.\n",
    "\n",
    "Now you will be given a pair of statements. Evaluate them, and output only the label and the explanation in a format: \n",
    "\n",
    "Label: your label\n",
    "Explanation: your explanation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_3_types = '''You are a diligent annotator who is performing a crowdsourcing task. You will be given pairs of texts, which are statements made by a political party. Your task is to evaluate whether they are consistent with each other or not. Additionally, we will ask you to briefly explain your reasoning behind choosing the label.\n",
    "\n",
    "Please familiarize yourself with the evaluation scale.\n",
    "Evaluation scale \n",
    "Unrelated, Consistent, Inconsistent\n",
    "\n",
    "Unrelated\n",
    "\n",
    "The Truth of A doesn't affect the Truth of B, and vice versa.\n",
    "\n",
    "Example 1:\n",
    "a) All apples are red. b) I like sunny weather.\n",
    "\n",
    "Example 2:\n",
    "a) We think people should be able to obtain sick leave for mild illnesses for up to seven days.\n",
    "b) We believe that the left-leaning bias in public broadcasting journalism is a significant issue.\n",
    "\n",
    "Example 3:\n",
    "a) We oppose expanding surveillance measures that use facial recognition technology.b) We believe that the deportation of illegal migrants will help alleviate the housing shortage in our country.\n",
    "\n",
    "Consistent\n",
    "\n",
    "If A is True, B is also likely to be True, and vice versa.\n",
    "\n",
    "Example 1:\n",
    "a) I like classical music. b) I am going to a classical music concert today.\n",
    "\n",
    "Example 2:\n",
    "a) We believe that the current government is failing to address population decline effectively.\n",
    "b) We believe the government should prioritize the traditional family model.\n",
    "\n",
    "Example 3:\n",
    "a) We believe that determining asylum eligibility before individuals reach the country would significantly relieve the taxpayers.b) We support stricter border protection measures due to the large-scale family reunification migration.\n",
    "\n",
    "Inconsistent statements can look differently, for example:\n",
    "\n",
    "Surface contradiction\n",
    "\n",
    "If A is True, B is False, and vice versa. No external/specialized knowledge is required to detect contradiction, just understanding logical form/language in A and B.\n",
    "\n",
    "Example 1: a) All kikis are bobable. b) This kiki is not bobable.\n",
    "Explanation: the logical form here is: a) All A are B. b) This A is not B. These are mutually exclusive.\n",
    "\n",
    "Example 2: a) I love kikis. b) I think kikis are the most terrible thing on Earth.\n",
    "Explanation: knowing language here is enough to see a contradiction.\n",
    "\n",
    "In both examples, we don't have to know what \"kiki\" and \"bobable\" mean in the real world (no external knowledge is needed). The \"surface\" is enough to see a contradiction. \n",
    "\n",
    "Example 3:a) I support the yellow party.\n",
    "b) I'm against the yellow party.\n",
    "Explanation: To support something and to be against something are the opposites. It is enough to understand the language to detect a contradiction - thus, it is a Surface contradiction.\n",
    "\n",
    "Example 4:a) We oppose sending weapons to war zones.\n",
    "b) We voted in favor of sending 50 tanks to a country that was attacked.\n",
    "Explanation: To \"oppose sending weapons\" and \"vote in favor of sending 50 tanks\" express opposing attitudes. No knowledge beyond A and B is needed to see a contradiction, so it is a Surface contradiction.\n",
    "\n",
    "Factual inconsistency\n",
    "\n",
    "if A is True, it challenges the Truth of B.\n",
    "Having external knowledge about the world beyond what is said in A and B is required to see inconsistency. This knowledge can include laws of physics, principles of economics, international relations, etc., as well as real-world events and empirical evidence.\n",
    "\n",
    "Example 1: a) We will provide extensive social benefits. b) We will minimize all the taxes.\n",
    "Explanation: based on empirical evidence, increasing social benefits (pensions, subsidies, etc.) usually requires having high taxes. This knowledge is needed to detect inconsistency.\n",
    "Note that A and B are not mutually exclusive - maybe the government will take debt or use other ways to increase social benefits.\n",
    "However, based only on the information we have + empirical evidence, we can assume that A and B are Factually inconsistent.\n",
    "\n",
    "Example 2:a) We care about climate change and want to switch to renewable energy.\n",
    "b) We are planning to build 120 coal plants next year.\n",
    "Explanation: Coal is not a renewable energy source, and burning coal contributes to climate change. This knowledge is required to see the inconsistency, and it is not mentioned in A and B. Thus, A and B are Factually inconsistent.\n",
    "\n",
    "\n",
    "Example 3:a) We don’t support subsidies in agriculture and think they are bad for competition.\n",
    "b) We demand the maintenance and future doubling of the agricultural diesel refund.\n",
    "Explanation: Text A is against subsidies in agriculture. Text B supports diesel refund, which can be considered as a type of a subsidy. Knowing this is required to see a contradiction, thus, it is a Factual inconsistency.\n",
    "\n",
    "Indirect inconsistency\n",
    "\n",
    "If A is True, it doesn't directly challenge the Truth of B, and vice versa.\n",
    "However, A and B go in opposite directions with respect to some value/ideology (V).\n",
    "\n",
    "Example 1: a) We support financial aid for unemployed people. b) We are against financial aid for single mothers.\n",
    "Explanation: In A, the author supports financial aid for people who might be struggling financially, while B is implicitly against supporting them (since single mothers might be struggling financially too). However, A doesn't challenge the truth of B - they are just going in opposite political directions.\n",
    "\n",
    "Example 2:a) We voted in favor of increasing data privacy regulations.\n",
    "b) We are working on introducing very precise targeted advertising.\n",
    "Explanation: In text B, one should know that targeted advertising requires extensive user data to be more precise. Thus, text B goes against data privacy, while text A supports it. It is an Indirect inconsistency.\n",
    "\n",
    "Example 3:a) Our government is committed to leading the disarmament negotiations.\n",
    "b) The defense ministry has announced an increase in the benefits available for volunteers in the army.\n",
    "Explanation: Text A expresses a stance against militarization (leading the disarmament negotiations), while text B is pro-militarization (recruiting more volunteers in the army). Thus, there is an Indirect inconsistency between A and B.\n",
    "\n",
    "Now you will be given a pair of statements. Evaluate them by choosing one out of three labels: Unrelated, Consistent, or Inconsistent. Output only the label and the explanation in a format: \n",
    "\n",
    "Label: your label\n",
    "Explanation: your explanation\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLaMA3-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = '''Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\n",
    "\n",
    "### Instruction:\n",
    "  {}\n",
    "\n",
    "  ### Input:\n",
    "  {}\n",
    "\n",
    "  ### Response:\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Nursulu_1\\Downloads\\ContraDetect\\automatic_stance_detection\\notebooks\\evaluating_models\\answers_mixtral_8_7B_Instruct_v0_1t_3_types.pkl\", 'rb') as f:\n",
    "    answers_mixtral_8_7B_Instruct_v0_1t_3_types = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers_mixtral_8_7B_Instruct_v0_1t_3_types = dict()\n",
    "answers_mixtral_8_7B_Instruct_v0_1t_3_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 474/474 [16:38<00:00,  2.11s/it]\n"
     ]
    }
   ],
   "source": [
    "instruction = instruction_3_types\n",
    "\n",
    "client = OpenAI(\n",
    "\tbase_url=\"https://api-inference.huggingface.co/v1/\",\n",
    "\tapi_key=hf_token\n",
    ")\n",
    "\n",
    "for i in tqdm(range(226, len(all_samples_df), 1)):\n",
    "    input = all_samples_df['Input'][i]\n",
    "    \n",
    "    messages = [\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": content.format(instruction, input)\n",
    "\t\t}\n",
    "\t]\n",
    "    completion = client.chat.completions.create(\n",
    "\t\tmodel=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", \n",
    "\t\tmessages=messages, \n",
    "\t\tmax_tokens=150\n",
    "\t)\n",
    "    \n",
    "    if i in range(5):\n",
    "        print(completion.choices[0].message)\n",
    "        \n",
    "    answers_mixtral_8_7B_Instruct_v0_1t_3_types[input] = completion.choices[0].message\n",
    "    with open('answers_mixtral_8_7B_Instruct_v0_1t_3_types.pkl', 'wb') as file:\n",
    "        pickle.dump(answers_mixtral_8_7B_Instruct_v0_1t_3_types, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers_mixtral_8_7B_Instruct_v0_1t_3_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/700 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 17\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m all_samples_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput\u001b[39m\u001b[38;5;124m'\u001b[39m][i]\n\u001b[0;32m      9\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m \t{\n\u001b[0;32m     11\u001b[0m \t\t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \t}\n\u001b[0;32m     15\u001b[0m     ]\n\u001b[1;32m---> 17\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_completion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m(\n\u001b[0;32m     18\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-3.2-1B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     19\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessages, \n\u001b[0;32m     20\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m\n\u001b[0;32m     21\u001b[0m     )\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'create'"
     ]
    }
   ],
   "source": [
    "instruction = instruction_5_types\n",
    "client = InferenceClient(\n",
    "    token=hf_token,\n",
    ")\n",
    "\n",
    "for i in tqdm(range(len(all_samples_df))):\n",
    "    input = all_samples_df['Input'][i]\n",
    "    \n",
    "    messages = [\n",
    "\t{\n",
    "\t\t\"role\": \"user\",\n",
    "\t\t\"content\": content.format(\n",
    "        instruction, input)\n",
    "\t}\n",
    "    ]\n",
    "\n",
    "    completion = client.chat_completion.create(\n",
    "        model=\"meta-llama/Llama-3.2-1B-Instruct\", \n",
    "        messages=messages, \n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    print(completion.choices[0].message)\n",
    "    break\n",
    "\n",
    "   \n",
    "    # print(full_response)\n",
    "    answers_llama3b_instruct_5_types[input] = completion\n",
    "    with open('answers_llama3b_instruct_5_types.pkl', 'wb') as file:\n",
    "        pickle.dump(answers_llama3b_instruct_5_types, file)\n",
    "    all_samples_df['Llama3-8B-Instruct'][i] = completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "client = InferenceClient(api_key=\"hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "\n",
    "messages = [\n",
    "\t{\n",
    "\t\t\"role\": \"user\",\n",
    "\t\t\"content\": \"What is the capital of France?\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", \n",
    "\tmessages=messages, \n",
    "\tmax_tokens=500\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('this face  will get you laid', 'a man looking in the camera and smiling')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_to_topic[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(caption_to_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a person using a bad internet browser\n",
      "Internet Explorer Y U no be good?\n",
      "a sportsman who lost a competition\n",
      "LeBron james y u no win championship?\n",
      "a person laying on a bad\n",
      "bed is comfy in the morning why u no comfy at night?\n",
      "a researcher\n",
      "OPeratins research Y U So difficult?!\n",
      "a chubby man\n",
      "miserableatbest y u so fat?\n",
      "a woman in warm clothes\n",
      "CALIFORNIA Y U SO COLD I GOTTA VACATION IN LAS VEGAS!!!\n",
      "a gamer playing at the computer\n",
      "online game y u no lag for them?\n",
      "a teenager using Iphone\n",
      "iPhone Y U no SIRI!\n",
      "a group of wild animals\n",
      "Y U HAVE CLAW? WE DNT LYK THE CLAW\n",
      "a hairdresser at work\n",
      "Hair Trimmer y u no trim while charging?\n"
     ]
    }
   ],
   "source": [
    "for example in examples_annotated:\n",
    "    topic = example.split(\"Topic: \")[-1] \n",
    "    print(topic)\n",
    "    txt = example.split(\"Caption: \")\n",
    "    txt = txt[1].split(\" Topic:\")\n",
    "    # print(txt)\n",
    "    caption = txt[0]\n",
    "    print(caption)\n",
    "    caption_to_topic.append((caption, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('brace yourselves <sep> everyone on facebok is about to become an expert in political science',\n",
       " 'being angry at people unproficient in politics')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_to_topic[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the word \"Topic:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(caption_to_topic)):\n",
    "    caption, topic = caption_to_topic[i]\n",
    "    if \"Topic: \" in topic:\n",
    "        topic = topic.replace(\"Topic: \", \"\")\n",
    "        caption_to_topic[i] = (caption, topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(caption_to_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes memes are very offensive and the model refused to respond. Remove the examples that are offensive according to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_remove = []\n",
    "for i in range(len(caption_to_topic)):\n",
    "    caption, topic = caption_to_topic[i]\n",
    "    if \"I cannot provide a response\" in topic:\n",
    "        indices_to_remove.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in indices_to_remove:\n",
    "    caption_to_topic.pop(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('caption_to_topic_angry.json', 'w') as file:\n",
    "    json.dump(caption_to_topic, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe to prepare a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angry = pd.DataFrame()\n",
    "df_angry['topic'] = [topic for caption, topic in caption_to_topic]\n",
    "df_angry['caption'] = [caption for caption, topic in caption_to_topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a person asking a rhetorical question about so...</td>\n",
       "      <td>NICK GIANELLA Y U ONLY LIKE CARS N GUNS?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>musician</td>\n",
       "      <td>Germy why u no listen to other bands!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A person using a bad reasoning process.</td>\n",
       "      <td>Heart! Y U NO logical?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a person</td>\n",
       "      <td>women y u no order ur own fries?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a sports fan</td>\n",
       "      <td>Purdue Fans Y U NO have no banners?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>a person wanting their post retweeted</td>\n",
       "      <td>@ASOT550  y u no retweet my post ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>a person not believing the signs</td>\n",
       "      <td>Y U NO  Believe the signs??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>a person being late</td>\n",
       "      <td>Jordan Bradley  Y U ALWAYS SO LATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>a student wanting school windows to be opened</td>\n",
       "      <td>NPHS windows  y u no open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>a man asking for a break</td>\n",
       "      <td>Y U NO  STOP FOR DQ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 topic  \\\n",
       "0    a person asking a rhetorical question about so...   \n",
       "1                                             musician   \n",
       "2              A person using a bad reasoning process.   \n",
       "3                                             a person   \n",
       "4                                         a sports fan   \n",
       "..                                                 ...   \n",
       "620              a person wanting their post retweeted   \n",
       "621                   a person not believing the signs   \n",
       "622                                a person being late   \n",
       "623      a student wanting school windows to be opened   \n",
       "624                           a man asking for a break   \n",
       "\n",
       "                                       caption  \n",
       "0    NICK GIANELLA Y U ONLY LIKE CARS N GUNS?!  \n",
       "1      Germy why u no listen to other bands!!!  \n",
       "2                       Heart! Y U NO logical?  \n",
       "3             women y u no order ur own fries?  \n",
       "4          Purdue Fans Y U NO have no banners?  \n",
       "..                                         ...  \n",
       "620         @ASOT550  y u no retweet my post ?  \n",
       "621                Y U NO  Believe the signs??  \n",
       "622         Jordan Bradley  Y U ALWAYS SO LATE  \n",
       "623                  NPHS windows  y u no open  \n",
       "624                       Y U NO  STOP FOR DQ?  \n",
       "\n",
       "[625 rows x 2 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_angry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angry.to_csv(\"df_angry.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('caption_to_topic_y_u_meme.json', 'w') as file:\n",
    "#     json.dump(caption_to_topic, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
